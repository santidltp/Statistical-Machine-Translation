# Tokenizer
#### requirest python 2.7
Tokenizer separates words from punctuation and makes them lower case for better alignment:
```
python tokenizer.py en.txt es.txt
```
Where en.txt and es.txt are the files you want to tokenize.
It will output en.txt_tk.txt es.txt_tk.txt as output, tokenized files.
